---
title: "SABRmetrics"
subtitle: "making baseball as much fun as doing your taxes"
author: "tut2_team5 <br> Mohamad, Adam and Jimmy"
institute: "University of Edinburgh"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      ratio: "16:9"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r load-packages, include = FALSE}
# Add any additional packages you need to this chunk
library(tidyverse)
library(tidymodels)
library(palmerpenguins)
library(knitr)
```

```{r setup, include=FALSE}
# For better figure resolution
knitr::opts_chunk$set(fig.dpi = 600, fig.asp = 0.618, out.height = "10%")
```


```{r load-data, echo = FALSE, messages = FALSE, results = FALSE, warning = FALSE, include = FALSE}
teams_cleaned <- read_csv("/cloud/project/data/teams-cleaned.csv")

#doing training split
set.seed(3)
teams_split <- initial_split(teams_cleaned, prop = 0.80)
teams_train <- training(teams_split)
teams_test <- testing(teams_split)

#have a lot of NAs for drs and uzr/uzr150/def, so he's something to deal with
#that:
teams_train %>%
  filter(is.na(mean_drs) == FALSE) -> teams_train_drs
teams_train %>%
  filter(is.na(mean_uzr) == FALSE) -> teams_train_uzr
```

class: center, middle

## We will be using SABRmetrics (the empirical analysis of baseball statistics)
## to look at how effectively different measurements for evaluating individual player performance predict team success.

---

class: inverse, center, middle

# Data

---

# Sources

- Our data was sourced from [retrosheet.org](retrosheet.org) and [fangraphs.com](fangraphs.com)

- We considered only the seasons from 1998-2019 because 1998 is after teams starting
recording data digitally and 1998 is the first season to have 30 teams.

- 2020 data was not considered because the season started later and only 60 games
were played which is much less than usual.

- The batting and fielding statistics from fangraphs were webscraped from fangraphs.

- The teams win and performance statistics were downloaded from the Chadwick Bureau
which was originally sourced from retrosheet.

.footnote[
  All UZR stats provided to fan graphs are courtesy of a legend called Michael Lichtman.
]

---

# Web scraping + Clean up

.pull-left[
- Fangraphs, unfortunately does not have ready to download datasets. However, so
a script was used to retrieve defensive and field statistics from the website.

- The website allows robots. However, it adds a CAPTCHA wall, if you make too
many requests so the website is not slowed for other users so it and also there
were many dead links which made the task much harder and take ages.

```{r captcha-demo}
tryCatch(
  expr = { 
    #scrape the data
  },
  error =  function(e){ 
      if(e[1] == "HTTP error 500."){ 
        #i.e. page does not exist
        #do not return anything
      }else{
        #stop scraping until I manually 
        #solve the CAPTCHA
      }
  }
)
```


]

.pull-right[

- Fielding and batting stats were scraped for each player for each season.

- which was later summarised into a smaller dataset that contained the weighted
average for each stat for each team.

- then joined each teams season statistics to the retrosheet's dataframe
which contained team performance metrics like win rate and whether they won the
world series or not.

]

---

#Team data

class: center, middle

```{r head, echo = FALSE, messages = FALSE}
kable(head(teams_cleaned[,1:10]), format = "html")
```
\+ 10 more cols.
---

class: inverse, middle, center

# Data Analysis

---

#Data Analysis

- We started by looking at each of the 18 variables separately and their relationship with the 
win rate. 

- and examined the residual vs. fitted plots to assess whether the linear model
is appropriate and evaluated the accuracy of the model predictions.

- For the sake of brevity, we will show the results for four random variables, two
offensive/batting and two defensive/fielding. The rest will be included in the code.

---

# Batting Average (AVG)

.pull-left[
```{r batting-average, message = FALSE, echo = FALSE}
#It's the same process for every variable, so I'll just walk
#through the first one.

#create graph, add linear model trend line
teams_train %>%
  ggplot(mapping = aes(x = mean_avg , y = win_rate)) +
  geom_point(size = 1.2, alpha = 0.35) +
  geom_smooth(method = "lm")

#linear model, note R squared and adjusted R squared
avg_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(win_rate ~ mean_avg, data = teams_train)

kable(tidy(avg_fit)[,1:4], format = "html")
```
]

.pull-right[
```{r res-avg, echo = FALSE, message = FALSE}
#residuals analysis
avg_aug <- augment(avg_fit$fit)
ggplot(data = avg_aug,
       aes(x = .fitted,
           y = .resid)) +
  geom_jitter() +
  geom_hline(yintercept = 0,
             linetype = "dashed")

kable(glance(avg_fit)[c(1:3)], format = "html")
```
]

---

# Isolated Power (ISO)

.pull-left[
```{r isolated-power,  message = FALSE, echo = FALSE}
teams_train %>%
  ggplot(mapping = aes(x = mean_iso , y = win_rate)) +
  geom_point(size = 1.2, alpha = 0.35) +
  geom_smooth(method = "lm")

iso_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(win_rate ~ mean_iso, data = teams_train)

kable(tidy(iso_fit)[,1:4], format = "html")

```
]

.pull-right[
```{r res-iso, echo = FALSE, message = FALSE}
#residuals analysis
iso_aug <- augment(iso_fit$fit)
ggplot(data = iso_aug,
       aes(x = .fitted,
           y = .resid)) +
  geom_jitter() +
  geom_hline(yintercept = 0,
             linetype = "dashed")

kable(glance(iso_fit)[c(1:3)], format = "html")
```
]

---

# Ultimate Zone Rating per 150 Games (UZR/150)

.pull-left[
```{r uzr-150, message = FALSE, echo = FALSE, warning = FALSE}
#It's the same process for every variable, so I'll just walk
#through the first one.

#create graph, add linear model trend line
teams_train %>%
  ggplot(mapping = aes(x = mean_uzr150 , y = win_rate)) +
  geom_point(size = 1.2, alpha = 0.35) +
  geom_smooth(method = "lm")

#linear model, note R squared and adjusted R squared
uzr150_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(win_rate ~ mean_uzr150, data = teams_train_uzr)

kable(tidy(uzr150_fit)[,1:4], format = "html")
```
]

.pull-right[
```{r res-uzr150, echo = FALSE, message = FALSE, warning = FALSE}
#residuals analysis
uzr150_aug <- augment(uzr150_fit$fit)
ggplot(data = uzr150_aug,
       aes(x = .fitted,
           y = .resid)) +
  geom_jitter() +
  geom_hline(yintercept = 0,
             linetype = "dashed")

kable(glance(uzr150_fit)[c(1:3)], format = "html")
```
]

---

# Wins Above Replacement (WAR)

.pull-left[
```{r war, message = FALSE, echo = FALSE, warning = FALSE}
#It's the same process for every variable, so I'll just walk
#through the first one.

#create graph, add linear model trend line
teams_train %>%
  ggplot(mapping = aes(x = mean_war , y = win_rate)) +
  geom_point(size = 1.2, alpha = 0.35) +
  geom_smooth(method = "lm")

#linear model, note R squared and adjusted R squared
war_fit <- linear_reg() %>%
  set_engine("lm") %>%
  fit(win_rate ~ mean_war, data = teams_train)

kable(tidy(war_fit)[,1:4], format = "html")
```
]

.pull-right[
```{r res-war, echo = FALSE, message = FALSE, warning = FALSE}
#residuals analysis
war_aug <- augment(war_fit$fit)
ggplot(data = war_aug,
       aes(x = .fitted,
           y = .resid)) +
  geom_jitter() +
  geom_hline(yintercept = 0,
             linetype = "dashed")

kable(glance(war_fit)[c(1:3)], format = "html")
```
]

---

### Analysis of Plots

- Observation of residual vs. fitted plots shows no discernible patterns, suggesting that the linear model is an adequate fit in all cases. 

- Observation of
adjusted R squared values shows that the linear models of WAR, Off, and wRC vs
Win Rate are best able to account for variance in data (values of 0.534, 0.442,
and 0.445 respectively). 

- Observation of plots does not suggest any cases of low
R squared resulting from a high number of outliers.

---

# How good were the predictions?

Finally, we examined how good the predictions by looking at the error from the
prediction on test samples. For example, this was for WAR.

```{r wins-above-replacement-prediction, echo = FALSE, message = FALSE, result = FALSE}
war_pred <- predict(war_fit, teams_test) %>%
  bind_cols(teams_test %>% select(win_rate, mean_war))
tibble(war_pred)

#Not quite sure how to evaluate the accuracy of these predictions, so I'm going 
#to look at the difference between predicted and actual, then calculate key 
#summary statistics.
war_pred %>%
  mutate(pred_diff = abs(.pred - win_rate)) -> war_pred2
```

```{r results, echo = FALSE}
print(paste("mean prediction error =", mean(war_pred2$pred_diff)))
print(paste("s.d. of  prediction error =", sd(war_pred2$pred_diff)))
```

---

class: inverse, center, middle

#THE END 
## Thanks for listening

